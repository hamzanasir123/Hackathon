---
sidebar_label: Glossary
sidebar_position: 4
title: Glossary
description: Definitions of key terms and concepts used throughout the course
---

# Glossary

This glossary provides definitions for key terms and concepts used throughout the Physical AI & Humanoid Robotics course.

## A

**Actuator**: A mechanical device that converts energy (typically electrical) into physical motion. In robotics, actuators control the movement of joints and other components.

**Adaptive Control**: A control method that adjusts its parameters in real-time based on changes in the system or environment.

**Admittance Control**: A control strategy that regulates the relationship between force and position, allowing compliant behavior in robotic systems.

## B

**Behavior Tree**: A hierarchical structure used to organize and execute robot behaviors in a modular and reactive way.

**Biomechanics**: The study of the structure, function, and motion of the mechanical aspects of biological systems, particularly relevant for humanoid robot design.

**Bipedal Locomotion**: The act of walking on two legs, a key capability for humanoid robots.

## C

**Cartesian Control**: Robot control in Cartesian (x, y, z) space rather than joint space.

**Cognitive Robotics**: A branch of robotics that focuses on creating robots with cognitive capabilities such as perception, reasoning, and learning.

**Collision Detection**: The computational problem of detecting when two or more objects come into contact.

**Compliance Control**: Control strategy that allows a robot to yield appropriately when interacting with the environment.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

## D

**Deep Learning**: A subset of machine learning based on artificial neural networks with representation learning.

**Dexterous Manipulation**: Fine motor control of robotic hands to perform complex manipulation tasks.

**Dynamic Movement Primitives (DMP)**: A method for representing and generating movements in robotics using dynamical systems.

## E

**Embodied AI**: Artificial intelligence systems that interact with the physical world through a body or robot platform.

**End-Effector**: The device at the end of a robotic arm designed to interact with the environment, such as a gripper or tool.

**Episodic Memory**: Memory of specific events that occurred at particular times and places, important for robot learning.

## F

**Forward Kinematics**: The use of joint parameters to compute the position and orientation of the end-effector.

**Force Control**: Control of the forces that a robot applies to its environment.

## G

**Gaussian Process**: A non-parametric method for regression and classification, often used in robotics for uncertainty modeling.

**Gripper**: A device for grasping and holding objects, typically located at the end of a robotic arm.

## H

**Haptic Feedback**: The use of touch and motion to communicate with users, important for robot teleoperation.

**Heuristic**: A practical approach to problem-solving that is not guaranteed to be optimal but is sufficient for a given set of goals.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots.

## I

**Inverse Kinematics**: The mathematical process of calculating joint parameters needed to place the end-effector at a desired position and orientation.

**Imitation Learning**: Learning a behavior by observing and mimicking demonstrations.

**Intention Recognition**: The ability of a robot to infer human intentions from observed behavior.

## J

**Jacobian Matrix**: A matrix that describes the relationship between joint velocities and end-effector velocities.

## K

**Kinematics**: The study of motion without considering the forces that cause the motion.

**Kinesthetic Teaching**: Teaching a robot by physically guiding it through motions.

## L

**Legged Locomotion**: The act of walking or running using legs, a key capability for humanoid robots.

**Learning from Demonstration (LfD)**: A method for teaching robots by demonstrating desired behaviors.

**LiDAR**: Light Detection and Ranging - a remote sensing method that uses light in the form of a pulsed laser to measure distances.

## M

**Manipulation**: The ability to physically interact with objects, including grasping, moving, and reorienting them.

**Motion Planning**: The task of finding a sequence of movements to achieve a goal while avoiding obstacles.

**Machine Learning**: A method of data analysis that automates analytical model building using algorithms that iteratively learn from data.

## N

**Navigation**: The ability of a robot to move through an environment, typically including localization, mapping, and path planning.

## P

**Path Planning**: The process of determining a route from a starting point to a destination.

**Perception**: The ability to interpret sensory information from the environment.

**Point Cloud**: A collection of data points in 3D space, typically generated by 3D scanners or LiDAR.

**Proactive Behavior**: Robot actions that anticipate future events or needs rather than simply reacting to them.

## R

**Reinforcement Learning**: A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System (ROS)**: Flexible framework for writing robot software, providing services designed for a heterogeneous computer cluster.

**ROS 2**: The second generation of the Robot Operating System with improved security, real-time capabilities, and production readiness.

## S

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Social Robot**: A robot designed to interact with humans in a natural, social manner.

**Sensor Fusion**: The process of combining sensory data from multiple sources to improve the accuracy and reliability of information.

## T

**Teleoperation**: Remote operation of a robot by a human operator.

**Trajectory Planning**: The process of creating a path that specifies position, velocity, and acceleration over time.

**Tactile Sensing**: Sensing of touch, pressure, and texture, important for dexterous manipulation.

## V

**Visual Servoing**: Control of robot motion using visual feedback from cameras.

**Vision-Language-Action (VLA)**: Systems that integrate visual perception, language understanding, and physical action.

**Virtual Reality (VR)**: A simulated experience that can be similar to or completely different from the real world, used for robot simulation and training.

## W

**Whole-Body Control**: Control of all degrees of freedom of a robot simultaneously, considering task priorities and constraints.

**Workspace**: The space within which a robot can operate, either physically or functionally.

## Z

**Zero-Moment Point (ZMP)**: A criterion for static and dynamic stability of legged robots during locomotion.

:::info
This glossary will be expanded as new terms are introduced throughout the course. Refer back to it whenever you encounter unfamiliar terminology.
:::